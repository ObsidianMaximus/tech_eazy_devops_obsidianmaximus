name: Terraform Apply

on:
  push:
    branches:
      - feature/assignment-2-s3-logging
  workflow_dispatch:
    inputs:
      stage:
        description: 'The environment to apply (dev or prod)'
        required: true
        default: 'dev'
        type: choice
        options:
        - dev
        - prod
      s3_bucket_name:
        description: 'A globally unique name for the S3 log bucket (e.g., my-unique-logs-12345)'
        required: true

jobs:
  terraform:
    name: Terraform Init & Apply
    runs-on: ubuntu-latest
    env:
      AWS_REGION: ap-south-1

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init
        run: terraform init
        working-directory: terraform

      - name: Zip Lambda function
        run: |
          cd terraform
          zip -r lambda.zip lambda_function.py
        shell: bash

      - name: Terraform Apply (auto-approve)
        # This is the key change. We now pass two variables to Terraform:
        # 1. The config file for the selected stage (e.g., dev_config.tfvars).
        # 2. The bucket name provided in the workflow inputs.
        run: |
          terraform apply \
            -var-file="${{ github.event.inputs.stage }}_config.tfvars" \
            -var="s3_bucket_name=${{ github.event.inputs.s3_bucket_name }}" \
            -auto-approve
        working-directory: terraform
